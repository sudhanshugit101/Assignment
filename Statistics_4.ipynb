{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76300f6e",
   "metadata": {},
   "source": [
    "#### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed6559",
   "metadata": {},
   "source": [
    "The PMF is used for discrete random variables, meaning variables that can only take on specific values. It gives the probability of each possible outcome. For example, if you flip a fair coin, the PMF for the outcome of the coin flip would be:\n",
    "\n",
    "P(X=0) = 0.5 (the probability of getting tails)\n",
    "P(X=1) = 0.5 (the probability of getting heads)\n",
    "Here, X is the random variable that represents the outcome of the coin flip, and the PMF gives the probability of each possible value of X.\n",
    "\n",
    "The PDF, on the other hand, is used for continuous random variables, meaning variables that can take on any value within a range. It gives the probability density of each possible outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81a6f1",
   "metadata": {},
   "source": [
    "#### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6cf0b",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a function used in probability theory to describe the cumulative probability of a random variable taking on a value less than or equal to a given value.\n",
    "\n",
    "For a discrete random variable, the CDF is defined as the sum of the probabilities of all values less than or equal to a given value. For a continuous random variable, the CDF is defined as the integral of the probability density function (PDF) up to a given value.\n",
    "\n",
    "For example, to find the probability that the score on the test is between 70 and 80, we would subtract the CDF at 70 from the CDF at 80:\n",
    "\n",
    "P(70 < X ≤ 80) = CDF(80) - CDF(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272be8ca",
   "metadata": {},
   "source": [
    "#### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a076f8",
   "metadata": {},
   "source": [
    "Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Height and weight of people: In many populations, the distribution of heights and weights tends to be approximately normal, with a bell-shaped curve.\n",
    "\n",
    "Test scores: The scores on many standardized tests, such as the SAT or GRE, tend to follow a normal distribution.\n",
    "\n",
    "Errors in measurement: When measuring physical quantities, such as length, temperature, or weight, there are always some errors involved, and these errors often follow a normal distribution.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution, and the standard deviation represents the spread or width of the distribution.\n",
    "\n",
    "When the mean is shifted to the left or right, the entire distribution is shifted along the x-axis. When the standard deviation is increased, the distribution becomes wider and flatter, with more probability density spread out over a larger range of values. When the standard deviation is decreased, the distribution becomes narrower and taller, with more probability density concentrated around the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c119f19",
   "metadata": {},
   "source": [
    "#### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a539ce68",
   "metadata": {},
   "source": [
    "It is a well-understood distribution: The normal distribution has been studied extensively and is well understood by statisticians and other researchers. This makes it easier to work with and analyze data that follows a normal distribution.\n",
    "\n",
    "It is versatile: The normal distribution can be used to model many different types of data, including measurements, test scores, and stock prices, among others.\n",
    "\n",
    "Here are a few real-life examples of normal distributions:\n",
    "\n",
    "Heights of people: The distribution of heights in a population tends to be approximately normal, with most people clustered around the mean height.\n",
    "\n",
    "IQ scores: IQ scores on standardized tests tend to follow a normal distribution, with a mean score of 100 and a standard deviation of 15.\n",
    "\n",
    "Blood pressure: Blood pressure measurements in a population tend to be normally distributed, with a mean value around 120/80 mmHg.\n",
    "\n",
    "Stock returns: Daily returns on many stocks and financial assets tend to be approximately normally distributed, with a mean return of zero and a standard deviation that varies depending on the asset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928b4cc",
   "metadata": {},
   "source": [
    "#### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89817862",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that represents the outcome of a single binary (yes/no) event with a fixed probability of success (p) and failure (1-p). It is named after the Swiss mathematician Jacob Bernoulli.\n",
    "\n",
    "An example of a Bernoulli distribution is flipping a coin, where the probability of getting heads (success) is p and the probability of getting tails (failure) is 1-p. Another example is rolling a die and getting a specific number, where the probability of getting the number is p and the probability of not getting the number is 1-p.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = x) = p^x * (1-p)^(1-x)\n",
    "\n",
    "where x is the outcome (0 or 1), and P(X = x) is the probability of getting that outcome.\n",
    "\n",
    "The binomial distribution represents the probability of getting exactly k successes in n independent Bernoulli trials, where each trial has the same probability of success (p). The PMF of the binomial distribution is given by:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where X is the random variable representing the number of successes, k is the number of successes, n is the total number of trials, p is the probability of success on each trial, and (n choose k) is the binomial coefficient, which represents the number of ways to choose k items from a set of n items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e543ce",
   "metadata": {},
   "source": [
    " #### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897674b3",
   "metadata": {},
   "source": [
    "z = (x - mu) / sigma\n",
    "\n",
    "where x is the value we want to standardize, mu is the mean of the distribution, and sigma is the standard deviation of the distribution.\n",
    "\n",
    "Plugging in the values, we get:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "Now, we use a standard normal distribution table: \n",
    "\n",
    "Using a standard normal distribution table, we find that the probability of a z-score being greater than 1 is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from this dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7901a",
   "metadata": {},
   "source": [
    "#### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc544d39",
   "metadata": {},
   "source": [
    "In a continuous uniform distribution, the random variable can take on any value within a given interval (range) with equal probability. For example, the height of an individual selected at random from a certain population might be modeled with a continuous uniform distribution, with the interval representing the range of possible heights.\n",
    "\n",
    "In the case of a discrete uniform distribution, the random variable can only take on a finite or countably infinite number of values with equal probability. For example, rolling a fair six-sided die produces a discrete uniform distribution, where the random variable can only take on the values 1, 2, 3, 4, 5, or 6 with equal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18f22b0",
   "metadata": {},
   "source": [
    "#### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0bf1c2",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a measure of how many standard deviations a data point is away from the mean of a distribution. It is calculated by subtracting the mean from the data point and dividing the result by the standard deviation:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where z is the z-score, x is the data point, μ is the mean of the distribution, and σ is the standard deviation of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062cd46",
   "metadata": {},
   "source": [
    "The z-score is important because it allows us to compare values from different distributions on a common scale. For example, if we have two distributions with different means and standard deviations, we cannot directly compare a value from one distribution to a value from the other distribution. However, if we convert both values to their z-scores, we can compare them on a common scale and determine which value is relatively higher or lower in its respective distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba848f",
   "metadata": {},
   "source": [
    "#### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be290b05",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in probability theory and statistics that states that the sum or the mean of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the underlying distribution of the individual random variables.\n",
    "\n",
    "In other words, the CLT states that as the sample size increases, the distribution of the sample means or sums approaches a normal distribution, regardless of the underlying distribution of the individual data points. This applies to any distribution with a finite variance, including the uniform, exponential, and even some non-symmetric distributions.\n",
    "\n",
    "The significance of the CLT is that it provides a mathematical basis for using the normal distribution to model a wide range of real-world phenomena. For example, it allows us to make inferences about the population mean and standard deviation based on a sample of data, even if we do not know the underlying distribution of the population. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca0dfab",
   "metadata": {},
   "source": [
    "#### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b3783",
   "metadata": {},
   "source": [
    "The assumptions of the CLT are a sufficiently large sample size, independent and identically distributed random variables, finite variance in the population, appropriate handling of outliers, and optionally a normal population distribution. If these assumptions are met, then the CLT can be applied to approximate the distribution of the sample means or sums."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0ce60",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2abb3cb2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
